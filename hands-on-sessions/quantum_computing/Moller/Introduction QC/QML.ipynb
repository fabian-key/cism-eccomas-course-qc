{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "# (WI4650) CodeLab 7 - QML\n",
    "### Problem: QML for ordinary differential equations\n",
    "\n",
    "In this Codelab you will learn how to implement a QML for the ordinary differential equation (ODE) $\\frac{df}{dx}=4x^3+x^2-2x-\\frac{1}{2}$ with $f(0)=1$ using Qadence.\n",
    "\n",
    "To get started, please do the following:\n",
    "1. Install [Qadence](https://pasqal-io.github.io/qadence/latest/) and some additional Python packages: `pip install jupyterlab qadence tqdm pandas seaborn`\n",
    "2. Start JubyterLab: `jupyter lab`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### A working QML example\n",
    "\n",
    "[Qadence](https://pasqal-io.github.io/qadence/latest/) is yet another quantum programming package that is particularly useful for developing QML applications."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# General imports\n",
    "from time import perf_counter\n",
    "from typing import Callable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "from numpy.random import uniform\n",
    "from qadence import (\n",
    "    QNN,\n",
    "    BasisSet,\n",
    "    QuantumCircuit,\n",
    "    chain,\n",
    "    feature_map,\n",
    "    hea,\n",
    "    ising_hamiltonian,\n",
    ")\n",
    "from torch import linspace, manual_seed, ones_like, optim, tensor, zeros_like\n",
    "from torch.autograd import grad\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup the function that we're trying to learn\n",
    "def ode(inputs: tensor) -> tensor:\n",
    "    return 4 * inputs**3 + inputs**2 - 2 * inputs - 0.5\n",
    "\n",
    "\n",
    "def analytical(inputs: tensor) -> tensor:\n",
    "    return inputs**4 + (1 / 3) * inputs**3 - inputs**2 - (1 / 2) * inputs + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us define some global parameters. You can later change these parameters to study how less or more qubits or a deeper quantum network influences the QML's performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_QUBITS, DEPTH, LEARNING_RATE, N_POINTS = 4, 3, 0.01, 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An essential part of a QML is the **ansatz**, that is, a parametric circuit whose parameters will be trained. \n",
    "Let us use the **hardware-efficient ansatz** ([`hea`](https://pasqal-io.github.io/qadence/latest/api/constructors/#qadence.constructors.hea.hea))."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ansatz = hea(n_qubits=N_QUBITS, depth=DEPTH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display(ansatz)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The other important part is the **feature map**, which encodes the input of our quantum network into the quantum circuit. Here, we use the **Chebyshev feature map**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fm = feature_map(n_qubits=N_QUBITS, param=\"x\", fm_type=BasisSet.CHEBYSHEV)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to define a **cost function**. Don't confuse this with the loss function that encodes our ODE. Let us choose the **transverse-field Ising Hamiltonian**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "obs = ising_hamiltonian(n_qubits=N_QUBITS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we are ready to build the *quantum circuit* and the **QNN model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "circuit = QuantumCircuit(N_QUBITS, chain(fm, ansatz))\n",
    "model = QNN(circuit=circuit, observable=obs, inputs=[\"x\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we need to implement the **loss function**. In our case, we implement the MSE loss function for the ODE $\\frac{df}{dx}=4x^3+x^2-2x-1/2$ with $f(0)=1$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loss_fn(inputs: tensor, outputs: tensor, ode: Callable[[tensor], tensor]) -> tensor:\n",
    "    dfdx = grad(inputs=inputs, outputs=outputs.sum(), create_graph=True)[0]\n",
    "    ode_loss = dfdx - ode(inputs)\n",
    "    boundary_loss = model(zeros_like(inputs)) - ones_like(inputs)\n",
    "    return ode_loss.pow(2).mean() + boundary_loss.pow(2).mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us train the QNN for 1000 epochs with randomly samples collocation points between (-1.0, 1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def benchmark(\n",
    "    domain_interval,\n",
    "    loss_fn,\n",
    "    ode,\n",
    "    num_epochs,\n",
    "    optimizer,\n",
    "    model,\n",
    "    analytical_sol,\n",
    "):\n",
    "    result_dict = {\"optimizer\": [], \"loss\": [], \"accuracy\": [], \"time\": [], \"epoch\": []}\n",
    "    sample_points = (\n",
    "        linspace(domain_interval[0], domain_interval[1], steps=100)\n",
    "        .reshape(-1, 1)\n",
    "        .detach()\n",
    "    )\n",
    "    for epoch in tqdm(range(num_epochs)):\n",
    "        start_time = perf_counter()\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # the collocation points are sampled randomly\n",
    "        cp = tensor(\n",
    "            uniform(\n",
    "                low=domain_interval[0], high=domain_interval[1], size=(N_POINTS, 1)\n",
    "            ),\n",
    "            requires_grad=True,\n",
    "        ).float()\n",
    "\n",
    "        loss = loss_fn(inputs=cp, outputs=model(cp), ode=ode)\n",
    "        end_time = perf_counter()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        analytic_sol = analytical_sol(sample_points)\n",
    "        dqc_sol = model(sample_points).detach().numpy()\n",
    "        result_dict[\"optimizer\"].append(optimizer.__class__.__name__)\n",
    "        result_dict[\"loss\"].append(loss.item())\n",
    "        result_dict[\"time\"].append(end_time - start_time)\n",
    "        result_dict[\"epoch\"].append(epoch + 1)\n",
    "        result_dict[\"accuracy\"].append(\n",
    "            (np.square(dqc_sol.flatten() - analytic_sol.flatten().numpy())).mean(axis=0)\n",
    "        )\n",
    "\n",
    "    return result_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some paramters\n",
    "interval = (-0.99, 0.99)\n",
    "optimizer = optim.Adam(model.parameters(), lr=LEARNING_RATE)\n",
    "num_epochs = 1000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_dict = benchmark(\n",
    "    interval, loss_fn, ode, num_epochs, optimizer, model, analytical\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame.from_dict(result_dict)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let us evaluate the solution predicted by the QNN. We start by visually comparing the analytical solution and the DQC model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_points = linspace(interval[0], interval[1], steps=100).reshape(-1, 1)\n",
    "dqc_sol = model(sample_points).detach().numpy()\n",
    "analytic_sol = analytical(sample_points)\n",
    "x_data = sample_points.detach().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_theme()\n",
    "\n",
    "plt.figure(figsize=(4, 4))\n",
    "plt.plot(x_data, analytic_sol.flatten(), color=\"gray\", label=\"Exact solution\")\n",
    "plt.plot(x_data, dqc_sol.flatten(), color=\"orange\", label=\"DQC solution\")\n",
    "plt.xlabel(r\"$x$\")\n",
    "plt.ylabel(r\"$\\frac{df}{dx}$\")\n",
    "plt.title(r\"$\\frac{df}{dx}=4x^3+x^2-2x-\\frac{1}{2}$ comparison\")\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plt.subplots()\n",
    "ax.set(yscale=\"log\")\n",
    "\n",
    "sns.lineplot(data=df, x=\"epoch\", y=\"accuracy\", ax=ax, label=\"accuracy\")\n",
    "sns.lineplot(data=df, x=\"epoch\", y=\"loss\", ax=ax, label=\"loss\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assignments\n",
    "\n",
    "Similar to the VQE assignment, your first task is to experiment with different parameters. You can use the code in the cells below to concatenate the results from multiple runs of the `benchmark` function, which should make it easier for you to visualize and analyse the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up and train another QNN from scratch\n",
    "def train_model(\n",
    "    optimizer_class, n_qubits, depth, num_epochs, domain_interval, learning_rate\n",
    "):\n",
    "    ansatz = hea(n_qubits=n_qubits, depth=depth)\n",
    "    fm = feature_map(n_qubits=n_qubits, param=\"x\", fm_type=BasisSet.CHEBYSHEV)\n",
    "    obs = ising_hamiltonian(n_qubits=n_qubits)\n",
    "    circuit = QuantumCircuit(n_qubits, chain(fm, ansatz))\n",
    "    model = QNN(circuit=circuit, observable=obs, inputs=[\"x\"])\n",
    "\n",
    "    optimizer = optimizer_class(model.parameters(), lr=learning_rate)\n",
    "    results = benchmark(\n",
    "        domain_interval, loss_fn, ode, num_epochs, optimizer, model, analytical\n",
    "    )\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_QUBITS, DEPTH, LEARNING_RATE, NUM_EPOCHS, DOMAIN_INTERVAL = (\n",
    "    4,\n",
    "    3,\n",
    "    0.01,\n",
    "    500,\n",
    "    (-0.99, 0.99),\n",
    ")\n",
    "\n",
    "dfs = []\n",
    "\n",
    "for optimizer in [optim.Adam, optim.SGD]:\n",
    "    result_dict = train_model(\n",
    "        optimizer,\n",
    "        N_QUBITS,\n",
    "        DEPTH,\n",
    "        NUM_EPOCHS,\n",
    "        DOMAIN_INTERVAL,\n",
    "        LEARNING_RATE,\n",
    "    )\n",
    "    dfs.append(pd.DataFrame.from_dict(result_dict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cdf = pd.concat(dfs)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "ax0 = plt.subplot(121)\n",
    "ax0.set(yscale=\"log\")\n",
    "\n",
    "\n",
    "ax1 = plt.subplot(122, sharex=ax0)\n",
    "ax1.set(yscale=\"log\")\n",
    "\n",
    "sns.lineplot(data=cdf, x=\"epoch\", y=\"accuracy\", ax=ax0, hue=\"optimizer\")\n",
    "sns.lineplot(data=cdf, x=\"epoch\", y=\"loss\", ax=ax1, hue=\"optimizer\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 1 - Number of qubits\n",
    "\n",
    "Tweak the QNN implementation by varying the number of qubits. Keep all other parameters unchanged. What effects does this have on the accuracy and cost of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your analysis here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 2 - Number of qubits\n",
    "\n",
    "Select a number of qubits that performs well and takes a reasonable time to train. Now tweak the QNN implementation by varying the depth of the ansatz. Keep all other parameters unchanged. What effects does this have on the accuracy and cost of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your analysis here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 3 - Feature maps\n",
    "\n",
    "Again select a combination of parameters that perfoms well and can be trained reasonably quickly. Now experiment with modifying the QNN implementation by changing the feature map (for instance [`BasisSet.FOURIER`](https://pasqal-io.github.io/qadence/v1.5.1/qadence/types/#qadence.types.BasisSet.FOURIER)). Keep all other parameters unchanged. What effects does this have on the accuracy and cost of your model?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your analysis here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 4 - Optimizers\n",
    "\n",
    "Finally, repeat the previous assignment by experiment with other [PyTorch optimizers](https://pytorch.org/docs/stable/optim.html), e.g., `optim.LBFGS`, `optim.RMSprop`, or `optim.SGD`. How does this change the training process?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your analysis here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Assignment 5 - A different equation\n",
    "\n",
    " Your final task is to use the experience you gained in the previous assignments to solve a different equation from scratch. Use a sensible combination of parameters which you found in the previous 4 assignment. Implement all necessary components to solve a different ODE, namely, $\\frac{df}{dy}=\\cos(x)$ with $y(0)=0$. How does your parameter choice perform for this equation? Which choice do you think has the biggest impact?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedback\n",
    "\n",
    "We are looking to improve these notebooks and would greatly appreciate your thoughts and feedback.\n",
    "\n",
    "What was your impression of this assignment? Do you have any suggestions about how we could improve this notebook for next year? Are there any changes you would make to the assignments that would make them more interesting or more instructive? Are there any assignments that you found too difficult, boring, or not instructive?\n",
    "\n",
    "Any and all feedback is welcome!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Your feedback here!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
